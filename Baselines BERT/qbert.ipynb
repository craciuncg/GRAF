{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNHI6ZwO6T+YYVGDFuGSUOA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"6fc80cdf7f9f4b4c80f88f5c542c9292":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_473f679dd51841a39f373ca5b0a246ff","IPY_MODEL_d2691c87f9db4e7da58db637e8068061","IPY_MODEL_ce01df67464a45c184e484c5f02e0c27"],"layout":"IPY_MODEL_42353101aab44bff9b69c08a8aa0c244"}},"473f679dd51841a39f373ca5b0a246ff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0cda7f393cd04f768a3eaa7a7f6a316c","placeholder":"​","style":"IPY_MODEL_098dce29235244e69ee5b7618f4af8b4","value":"Map: 100%"}},"d2691c87f9db4e7da58db637e8068061":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_737ca7897d0546a9891762431b3ea2e1","max":25086,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ac5b99a7860745faac650cde1218703b","value":25086}},"ce01df67464a45c184e484c5f02e0c27":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_33f7483762cc45f7be5fb4ed045d9955","placeholder":"​","style":"IPY_MODEL_6c20bd1feae442cd90137dea49e39165","value":" 25086/25086 [00:19&lt;00:00, 1356.07 examples/s]"}},"42353101aab44bff9b69c08a8aa0c244":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0cda7f393cd04f768a3eaa7a7f6a316c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"098dce29235244e69ee5b7618f4af8b4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"737ca7897d0546a9891762431b3ea2e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac5b99a7860745faac650cde1218703b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"33f7483762cc45f7be5fb4ed045d9955":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c20bd1feae442cd90137dea49e39165":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"af543d8b8a5149e0a82c0995bf780150":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3ec4305e16d34c538a71e67cf2b86900","IPY_MODEL_98b75062b16d4e148ba5470420cef268","IPY_MODEL_9c3871e0d52d4fed84d74568a75364f1"],"layout":"IPY_MODEL_80547d2f4fe2495fa39f11e4479465fc"}},"3ec4305e16d34c538a71e67cf2b86900":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c7abe3d14b1d41e6b209dde959b5d066","placeholder":"​","style":"IPY_MODEL_57179eb3faf642cab6f9f0f48780e793","value":"Map: 100%"}},"98b75062b16d4e148ba5470420cef268":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d174ca95b4142438379b0a1764191ed","max":3633,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1fa3781bbb794315b7addc3cfc194ef3","value":3633}},"9c3871e0d52d4fed84d74568a75364f1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_34c6351d3d314bba99ed59779b47a8f2","placeholder":"​","style":"IPY_MODEL_bf641dab07b14485ad65f7f1b72f73e2","value":" 3633/3633 [00:02&lt;00:00, 1638.36 examples/s]"}},"80547d2f4fe2495fa39f11e4479465fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c7abe3d14b1d41e6b209dde959b5d066":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57179eb3faf642cab6f9f0f48780e793":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1d174ca95b4142438379b0a1764191ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1fa3781bbb794315b7addc3cfc194ef3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"34c6351d3d314bba99ed59779b47a8f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf641dab07b14485ad65f7f1b72f73e2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kmP1GYhAAC8k","executionInfo":{"status":"ok","timestamp":1724763602087,"user_tz":-180,"elapsed":30283,"user":{"displayName":"Andrei Adrian Răgman","userId":"14875774624612539282"}},"outputId":"cd52e259-e1df-4505-e664-0bf94a729aa0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/My Drive/juro/QBert\n"]}],"source":["# prompt: connect to drive to the juro/Qbert directory\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","%cd '/content/drive/My Drive/juro/QBert'\n"]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from transformers import AutoModel, AutoTokenizer, AutoModel"],"metadata":{"id":"YJcYHTgdBBd4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class QBERT(nn.Module):\n","\n","    def __init__(\n","        self,\n","        variant='readerbench/jurBERT-base',\n","        no_answers=3,\n","        *args,\n","        **kwargs\n","    ) -> None:\n","        super().__init__(*args, **kwargs)\n","\n","        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","        self.tokenizer = AutoTokenizer.from_pretrained(variant)\n","        self.bert = AutoModel.from_pretrained(variant)\n","        self.bert.to(self.device)\n","\n","        self.embedding_size = self.bert.config.hidden_size\n","        print(self.embedding_size)\n","        self.mlp = nn.Sequential(\n","            nn.Linear(self.embedding_size, 1),\n","            nn.Sigmoid()\n","        )\n","        self.mlp.to(self.device)\n","\n","    def forward(self, q, a):\n","        qa_pair = torch.cat((q, a), dim=-1)\n","        out = self.bert(qa_pair).last_hidden_state[:, 0, :]\n","        out = self.mlp(out)\n","        return out"],"metadata":{"id":"jwjZueDYBCvm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_4VtaOPG7HYL","executionInfo":{"status":"ok","timestamp":1724763656577,"user_tz":-180,"elapsed":17106,"user":{"displayName":"Andrei Adrian Răgman","userId":"14875774624612539282"}},"outputId":"b6fbd1f0-a4a1-4d9c-830e-4e68484e138e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datasets\n","  Downloading datasets-2.21.0-py3-none-any.whl.metadata (21 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n","Collecting pyarrow>=15.0.0 (from datasets)\n","  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n","Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n","Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.7.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Downloading datasets-2.21.0-py3-none-any.whl (527 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.3/527.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: xxhash, pyarrow, dill, multiprocess, datasets\n","  Attempting uninstall: pyarrow\n","    Found existing installation: pyarrow 14.0.2\n","    Uninstalling pyarrow-14.0.2:\n","      Successfully uninstalled pyarrow-14.0.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n","ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed datasets-2.21.0 dill-0.3.8 multiprocess-0.70.16 pyarrow-17.0.0 xxhash-3.5.0\n"]}]},{"cell_type":"code","source":["from transformers import AutoModel, AutoTokenizer, AutoModel\n","import torch\n","import utils\n","from torch.utils.data import DataLoader\n","from datasets import load_dataset\n","import transformers\n","from torch.utils.data import Sampler\n","from collections import defaultdict\n","from datasets import DatasetDict"],"metadata":{"id":"ytX6-S0xoGjg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["TRAIN_SET = 'train_law.csv'\n","VALIDATION_SET = 'validation_law.csv'\n","\n","tokenizer = AutoTokenizer.from_pretrained('readerbench/jurBERT-base')\n","\n","rows_train = utils.load_csv('train_law.csv')\n","rows_train = [row for row in rows_train if len(row[-1]) == 1]\n","\n","rows_validation = utils.load_csv('validation_law.csv')\n","rows_validation = [row for row in rows_validation if len(row[-1]) == 1]"],"metadata":{"id":"bDeg6LbqoKEQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import re\n","\n","def remove_number_from_string(input_string):\n","    result = re.sub(r'^\\d+\\s*', '', input_string)\n","    return result"],"metadata":{"id":"3P-UgYx7oOdH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_set = load_dataset('csv', data_files=TRAIN_SET)['train']\n","validation_set = load_dataset('csv', data_files=VALIDATION_SET)['train']\n","\n","# Removed 'context' column\n","train_set = train_set.remove_columns(column_names=['choice_index','context','bert_input','prompt'])\n","validation_set = validation_set.remove_columns(column_names=['choice_index','context','bert_input','prompt'])\n","\n","train_set = train_set.rename_column(original_column_name='question_index', new_column_name='index')\n","validation_set = validation_set.rename_column(original_column_name='question_index', new_column_name='index')\n"],"metadata":{"id":"UPBivJvYoO2F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# TODO: Remove numbers, lowercase, tokenize\n","\n","def tokenize(samples):\n","    index = samples['index']\n","    question = samples['question']\n","    choice = samples['choice']\n","    label = samples['label']\n","\n","    letter = choice[0]\n","    q = remove_number_from_string(question)[1:].strip().lower()\n","    c = choice[2:].strip().lower()\n","\n","    tokenized_samples = {}\n","\n","    tokenized_question = tokenizer(q, padding=False, truncation=False, add_special_tokens=False)\n","    tokenized_choice = tokenizer(c, padding=False, truncation=False, add_special_tokens=False)\n","\n","    # tokenized_samples['question_ids'] = tokenized_question['input_ids']\n","    for k,v in tokenized_question.items():\n","        tokenized_samples['question_' + k] = v\n","\n","    for k,v in tokenized_choice.items():\n","        tokenized_samples['choice_' + k] = v\n","\n","    #tokenized_samples['choice_ids'] = tokenized_choice['input_ids']\n","\n","    tokenized_samples['index'] = index\n","\n","    if letter == label:\n","        tokenized_samples['label'] = 1\n","    else:\n","        tokenized_samples['label'] = 0\n","\n","    return tokenized_samples"],"metadata":{"id":"cynoS9EjoT8Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_encoded = train_set.map(tokenize, batched=False, remove_columns=['question', 'choice'])\n","validation_encoded = validation_set.map(tokenize, batched=False, remove_columns=['question', 'choice'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["6fc80cdf7f9f4b4c80f88f5c542c9292","473f679dd51841a39f373ca5b0a246ff","d2691c87f9db4e7da58db637e8068061","ce01df67464a45c184e484c5f02e0c27","42353101aab44bff9b69c08a8aa0c244","0cda7f393cd04f768a3eaa7a7f6a316c","098dce29235244e69ee5b7618f4af8b4","737ca7897d0546a9891762431b3ea2e1","ac5b99a7860745faac650cde1218703b","33f7483762cc45f7be5fb4ed045d9955","6c20bd1feae442cd90137dea49e39165","af543d8b8a5149e0a82c0995bf780150","3ec4305e16d34c538a71e67cf2b86900","98b75062b16d4e148ba5470420cef268","9c3871e0d52d4fed84d74568a75364f1","80547d2f4fe2495fa39f11e4479465fc","c7abe3d14b1d41e6b209dde959b5d066","57179eb3faf642cab6f9f0f48780e793","1d174ca95b4142438379b0a1764191ed","1fa3781bbb794315b7addc3cfc194ef3","34c6351d3d314bba99ed59779b47a8f2","bf641dab07b14485ad65f7f1b72f73e2"]},"id":"xPdMlQhboVNi","executionInfo":{"status":"ok","timestamp":1724765318953,"user_tz":-180,"elapsed":22376,"user":{"displayName":"Andrei Adrian Răgman","userId":"14875774624612539282"}},"outputId":"4f6a3fd0-66d3-412b-f8d0-726c2afb1733"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/25086 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6fc80cdf7f9f4b4c80f88f5c542c9292"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/3633 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af543d8b8a5149e0a82c0995bf780150"}},"metadata":{}}]},{"cell_type":"code","source":["\n","class GroupedByIndexSampler(Sampler):\n","    def __init__(self, data_source, shuffle=False):\n","        self.data_source = data_source\n","        self.shuffle = shuffle\n","\n","        # Group indices by the \"index\" column value\n","        self.index_groups = defaultdict(list)\n","        for idx, item in enumerate(data_source):\n","            self.index_groups[item['index']].append(idx)\n","\n","        # Convert the defaultdict to a list of index groups\n","        self.groups = list(self.index_groups.values())\n","\n","    def __iter__(self):\n","        # Shuffle the groups if you want (optional)\n","        if not self.shuffle:\n","            torch.manual_seed(0)  # For reproducibility\n","        indices = torch.randperm(len(self.groups)).tolist()\n","        for i in indices:\n","            yield self.groups[i]\n","\n","    def __len__(self):\n","        return len(self.groups)\n","\n","# %%\n","def collate_fn(samples):\n","    max_length_questions = max([len(sample['question_input_ids']) for sample in samples])\n","    max_length_choice = max([len(sample['choice_input_ids']) for sample in samples])\n","\n","    for i, sample in enumerate(samples):\n","        question_input_ids = sample['question_input_ids']\n","        question_token_type_ids = sample['question_token_type_ids']\n","        question_attention_mask = sample['question_attention_mask']\n","\n","        choice_input_ids = sample['choice_input_ids']\n","        choice_token_type_ids = sample['choice_token_type_ids']\n","        choice_attention_mask = sample['choice_attention_mask']\n","\n","        question_input_ids = question_input_ids + [0] * (max_length_questions - len(question_input_ids))\n","        question_token_type_ids = question_token_type_ids + [0] * (max_length_questions - len(question_token_type_ids))\n","        question_attention_mask = question_attention_mask + [0] * (max_length_questions - len(question_attention_mask))\n","\n","        choice_input_ids = choice_input_ids + [0] * (max_length_choice - len(choice_input_ids))\n","        choice_token_type_ids = choice_token_type_ids + [0] * (max_length_choice - len(choice_token_type_ids))\n","        choice_attention_mask = choice_attention_mask + [0] * (max_length_choice - len(choice_attention_mask))\n","\n","        samples[i]['question_input_ids'] = question_input_ids\n","        samples[i]['question_token_type_ids'] = question_token_type_ids\n","        samples[i]['question_attention_mask'] = question_attention_mask\n","\n","        samples[i]['choice_input_ids'] = choice_input_ids\n","        samples[i]['choice_token_type_ids'] = choice_token_type_ids\n","        samples[i]['choice_attention_mask'] = choice_attention_mask\n","\n","    collated_samples = {\n","        'question_input_ids': [],\n","        'question_token_type_ids': [],\n","        'question_attention_mask': [],\n","        'choice_input_ids': [],\n","        'choice_token_type_ids': [],\n","        'choice_attention_mask': [],\n","        'label': [],\n","        'index': []\n","    }\n","\n","    for key, l in collated_samples.items():\n","        for sample in samples:\n","            l.append(sample[key])\n","        collated_samples[key] = torch.tensor(collated_samples[key])\n","\n","    return collated_samples\n","\n","sampler = GroupedByIndexSampler(validation_encoded)\n","validation_dataloader = DataLoader(validation_encoded, batch_sampler=sampler, collate_fn=collate_fn, pin_memory=False)\n","train_dataloader = DataLoader(train_encoded, batch_sampler=sampler, collate_fn=collate_fn, pin_memory=False)\n","\n","def col_batch(batch):\n","    cbatch = {\n","        'question' : {\n","            'input_ids': [],\n","            'attention_mask': [],\n","            'token_type_ids': []\n","        },\n","        'choice' : {\n","            'input_ids': [],\n","            'attention_mask': [],\n","            'token_type_ids': []\n","        },\n","        'label': [],\n","        'index': []\n","    }\n","\n","    l = len(batch['label'])\n","\n","    cbatch['question']['input_ids'] = batch['question_input_ids']\n","    cbatch['question']['attention_mask'] = batch['question_attention_mask']\n","    cbatch['question']['token_type_ids'] = batch['question_token_type_ids']\n","\n","    cbatch['choice']['input_ids'] = batch['choice_input_ids']\n","    cbatch['choice']['attention_mask'] = batch['choice_attention_mask']\n","    cbatch['choice']['token_type_ids'] = batch['choice_token_type_ids']\n","\n","    cbatch['question']['input_ids'] = torch.cat((torch.tensor([[tokenizer.cls_token_id]] * l), cbatch['question']['input_ids']), dim=-1).int()\n","    cbatch['question']['attention_mask'] = torch.cat((torch.tensor([[1]] * l), cbatch['question']['attention_mask']), dim=-1).int()\n","    cbatch['question']['token_type_ids'] = torch.cat((torch.tensor([[0]] * l), cbatch['question']['token_type_ids']), dim=-1).int()\n","\n","    cbatch['choice']['input_ids'] = torch.cat((torch.tensor([[tokenizer.sep_token_id]] * l), cbatch['choice']['input_ids']), dim=-1).int()\n","    cbatch['choice']['attention_mask'] = torch.cat((torch.tensor([[1]] * l), cbatch['choice']['attention_mask']), dim=-1).int()\n","    cbatch['choice']['token_type_ids'] = torch.cat((torch.tensor([[0]] * l), cbatch['choice']['token_type_ids']), dim=-1).int()\n","\n","    cbatch['choice']['input_ids'] = torch.cat((cbatch['choice']['input_ids'], torch.tensor([[tokenizer.sep_token_id]] * l)), dim=-1).int()\n","    cbatch['choice']['attention_mask'] = torch.cat((cbatch['choice']['attention_mask'], torch.tensor([[1]] * l)), dim=-1).int()\n","    cbatch['choice']['token_type_ids'] = torch.cat((cbatch['choice']['token_type_ids'], torch.tensor([[0]] * l)), dim=-1).int()\n","\n","    cbatch['label'] = batch['label'].int()\n","    cbatch['index'] = batch['index'].int()\n","\n","    return cbatch\n","\n","import gc\n","def clean_batch(batch):\n","    if type(batch) != dict:\n","        del batch\n","        #gc.collect()\n","        #torch.cuda.empty_cache()\n","        return\n","\n","    for _,v in batch.items():\n","        clean_batch(v)\n","\n","\n","\n"],"metadata":{"id":"4U8NVKrJKVo5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = QBERT()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rOtUxCSvpqH7","executionInfo":{"status":"ok","timestamp":1724765326984,"user_tz":-180,"elapsed":1382,"user":{"displayName":"Andrei Adrian Răgman","userId":"14875774624612539282"}},"outputId":"ce3e9fcb-32ca-4898-ef7c-ab7f32238394"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["768\n"]}]},{"cell_type":"code","source":["import torch.nn as nn\n","\n","\n","EPOCHS = 30\n","lr = 1e-4\n","optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n","loss_fn = nn.MSELoss()\n","\n","# %%\n","# for batch in dataloader:\n","#     cbatch = col_batch(batch)\n","\n","#     label = cbatch['label']\n","#     question = cbatch['question']\n","#     choice = cbatch['choice']\n","#     print(model(question, choice))\n","#     break\n","import gc\n","from tqdm import tqdm\n","epoch_train_loss = []\n","epoch_eval_loss = []\n","step_train_loss = []\n","step_eval_loss = []\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","for epoch in range(EPOCHS):\n","\n","    print('EPOCH', epoch)\n","    print('TRAIN')\n","    train_loss = 0\n","    model.train()\n","    for batch in tqdm(train_dataloader, total=len(train_dataloader)):\n","        cbatch = col_batch(batch)\n","\n","        for k, v in cbatch['question'].items():\n","            cbatch['question'][k] = v.to(device)\n","\n","        for k, v in cbatch['choice'].items():\n","            cbatch['choice'][k] = v.to(device)\n","\n","        cbatch['label'] = cbatch['label'].float().to(device)\n","\n","        out1 = model(cbatch['question']['input_ids'], cbatch['choice']['input_ids']).squeeze()\n","        loss = loss_fn(out1, cbatch['label'])\n","\n","        del out1\n","        del cbatch['question']['input_ids']\n","        del cbatch['question']['token_type_ids']\n","        del cbatch['question']['attention_mask']\n","\n","        del cbatch['choice']['input_ids']\n","        del cbatch['choice']['token_type_ids']\n","        del cbatch['choice']['attention_mask']\n","\n","        del cbatch['label']\n","        del cbatch['index']\n","\n","        del batch\n","        del cbatch\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        step_train_loss.append(loss.item())\n","        train_loss += step_train_loss[-1]\n","\n","        for _ in range(1):\n","            gc.collect()\n","            torch.cuda.empty_cache()\n","\n","    train_loss = train_loss / len(train_dataloader)\n","    epoch_train_loss.append(train_loss)\n","\n","    print(f\"Loss training epoch {epoch + 1}: {train_loss}\")\n","\n","    with open('train_loss.txt', 'a') as f:\n","        f.write(f\"Loss training epoch {epoch + 1}: {train_loss}\\n\")\n","        f.write(f\"Individual loss {epoch + 1}: {step_train_loss}\\n\")\n","\n","    print('EVAL')\n","    eval_loss = 0\n","    model.eval()\n","    for batch in tqdm(validation_dataloader, total=len(validation_dataloader)):\n","        cbatch = col_batch(batch)\n","\n","        for k, v in cbatch['question'].items():\n","            cbatch['question'][k] = v.to(device)\n","\n","        for k, v in cbatch['choice'].items():\n","            cbatch['choice'][k] = v.to(device)\n","\n","        cbatch['label'] = cbatch['label'].to(device)\n","\n","        with torch.no_grad():\n","            label = cbatch['label'].float()\n","            question = cbatch['question']['inputs_ids']\n","            choice = cbatch['choice']['inpus_ids']\n","            out1 = model(question, choice).squeeze()\n","            loss = loss_fn(out1, label)\n","\n","        step_eval_loss.append(loss.item())\n","        eval_loss += step_eval_loss[-1]\n","\n","        #for k, v in cbatch['question'].items():\n","        del cbatch['question']['input_ids']\n","        del cbatch['question']['token_type_ids']\n","        del cbatch['question']['attention_mask']\n","\n","        del cbatch['choice']['input_ids']\n","        del cbatch['choice']['token_type_ids']\n","        del cbatch['choice']['attention_mask']\n","\n","        #for k, v in cbatch['choice'].items():\n","\n","        del cbatch['label']\n","        del cbatch['index']\n","\n","        del batch\n","        del cbatch\n","        del loss\n","        del out1\n","        del out2\n","        del label\n","        del question\n","        del choice\n","        for _ in range(1):\n","            gc.collect()\n","            torch.cuda.empty_cache()\n","\n","    eval_loss = eval_loss / len(validation_dataloader)\n","    epoch_eval_loss.append(eval_loss)\n","    print(f\"Loss testing epoch {epoch + 1}: {eval_loss}\")\n","\n","    with open('test_loss.txt', 'a') as f:\n","        f.write(f\"Loss testing epoch {epoch + 1}: {eval_loss}\\n\")\n","        f.write(f\"Individual loss {epoch + 1}: {epoch_eval_loss}\\n\")\n","\n","torch.save(self.model.state_dict(), \"qbert_model.plt\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5PD7F_b9oeXL","outputId":"1db61ff4-191a-408c-90e0-89dca241ba53"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["EPOCH 0\n","TRAIN\n"]},{"output_type":"stream","name":"stderr","text":["  1%|▏         | 4/295 [00:59<1:24:50, 17.49s/it]"]}]}]}